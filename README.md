# ğŸ¤Ÿ ASL Hand Gesture Recognition with Real-Time Sentence Building

This project is a real-time American Sign Language (ASL) alphabet recognition system using a webcam. It detects hand gestures representing ASL letters and dynamically builds words or sentences based on the predictions.

### ğŸ§  Tech Stack

- Python
- OpenCV
- TensorFlow / Keras
- NumPy

---

## ğŸ“Œ Features

- ğŸ”¤ Real-time ASL letter prediction via webcam
- ğŸ§  Trained deep learning model (CNN) on ASL dataset
- ğŸ§¾ Automatic sentence building from recognized letters
- âŒ¨ï¸ Spacebar adds a space between words
- ğŸ§¹ Press `c` to clear the sentence
- ğŸ›‘ Press `q` to quit the app

---

## ğŸ“‚ Project Structure

asl-recognition/
â”‚
â”œâ”€â”€ asl_model.h5 # Trained Keras model for letter recognition
â”œâ”€â”€ label_map.npy # Label-to-letter mapping dictionary
â”œâ”€â”€ predict.py # Main prediction and sentence building script
â””â”€â”€ README.md # Project documentation




ğŸ– How It Works
A rectangular region of interest (ROI) appears on the webcam.

Place your hand gesture inside the box.

The model processes each frame and predicts the ASL letter.

It only adds a letter to the sentence after confirming it over a few frames (to avoid flickering).
Use keyboard keys:

Space: Add space

c: Clear sentence

q: Quit

ğŸ™Œ Acknowledgments
ASL Alphabet Dataset - Kaggle

OpenCV and TensorFlow community


